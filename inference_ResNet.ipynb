{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bf749ff",
   "metadata": {},
   "source": [
    "# ResNet Model Inference — Field Reconstruction Benchmark\n",
    "\n",
    "This notebook demonstrates **inference** using a pre-trained ResNet model to reconstruct 2D fields from sparse sensor data.\n",
    "\n",
    "---\n",
    "\n",
    "**How to use this notebook:**\n",
    "\n",
    "1. **First**, run the second code cell to define the main inference function (`run_reconstruction_inference`).\n",
    "2. **Second**, run the first code cell to perform inference.  \n",
    "   - You may set the `sample_idx` to view reconstructions for different test samples.\n",
    "\n",
    "**Parameters you can use:**\n",
    "- `sample_idx`: Change this to see different test samples reconstructed.\n",
    "- `num_snapshots` and `sen_num`: **Do not change these** unless you have trained your model to exactly match those settings.\n",
    "    - With the provided pretrained weights and data in this repo, **you should only modify `sample_idx`** for valid inference.\n",
    "\n",
    "**Important:**  \n",
    "- If you change `num_snapshots` or `sen_num` to values _other than_ those used during training, the loaded model weights will no longer be valid or give meaningful results.\n",
    "- By default, this notebook uses:  \n",
    "  - `num_snapshots=5000`\n",
    "  - `sen_num=100`  \n",
    "  which matches the default pretrained ResNet weights in the repo.\n",
    "\n",
    "---\n",
    "\n",
    "**Note on CNN Inference:**\n",
    "\n",
    "- **This notebook is only for ResNet model inference.**\n",
    "- If you want to use the **Simple CNN** method, you must train it first and then use the relevant inference cells provided in `test.ipynb`.  \n",
    "- There is no standalone inference script for the CNN; all CNN-related demo, training, and inference code is in `test.ipynb`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676434a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_reconstruction_inference(num_snapshots=5000, sen_num=100, sample_idx=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07e813a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ CUDA not available. Running on CPU.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.interpolate import griddata\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "\n",
    "# Check device availability\n",
    "device = 'cuda' \n",
    "if not torch.cuda.is_available():\n",
    "    device = 'cpu'\n",
    "    print(\"⚠️ CUDA not available. Running on CPU.\")\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, dropout_rate=0.1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, padding='same')\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.dropout = nn.Dropout2d(dropout_rate)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, padding='same')\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.shortcut = nn.Identity()\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=1, padding='same')\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.shortcut(x)\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.dropout(out)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += shortcut\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNetReconstructor(nn.Module):\n",
    "    def __init__(self, dim_1, dim_2):\n",
    "        super(ResNetReconstructor, self).__init__()\n",
    "        \n",
    "        self.initial_conv = nn.Conv2d(2, 64, kernel_size=5, padding='same')\n",
    "        self.initial_bn = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.res1 = ResidualBlock(64, 64, dropout_rate=0.1)\n",
    "        self.res2 = ResidualBlock(64, 64, dropout_rate=0.1)\n",
    "        \n",
    "        self.res3 = ResidualBlock(64, 128, dropout_rate=0.2)\n",
    "        self.res4 = ResidualBlock(128, 128, dropout_rate=0.2)\n",
    "        \n",
    "        self.res_added_1 = ResidualBlock(128, 128, dropout_rate=0.2) \n",
    "        self.res_added_2 = ResidualBlock(128, 128, dropout_rate=0.2) \n",
    "        \n",
    "        self.res5 = ResidualBlock(128, 64, dropout_rate=0.1) \n",
    "        \n",
    "        self.final_conv = nn.Conv2d(64, 1, kernel_size=3, padding='same')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.initial_bn(self.initial_conv(x)))\n",
    "        \n",
    "        x = self.res1(x)\n",
    "        x = self.res2(x)\n",
    "        x = self.res3(x)\n",
    "        x = self.res4(x)\n",
    "        \n",
    "        x = self.res_added_1(x) \n",
    "        x = self.res_added_2(x) \n",
    "        \n",
    "        x = self.res5(x)\n",
    "        \n",
    "        x = self.final_conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# --- Main Inference Function ---\n",
    "\n",
    "def run_reconstruction_inference(num_snapshots=5000, sen_num=100, va=300, sample_idx=10):\n",
    "    \"\"\"\n",
    "    Performs field reconstruction inference using a trained ResNet model.\n",
    "\n",
    "    Args:\n",
    "        num_snapshots (int): The total number of snapshots to load from the data.\n",
    "        sen_num (int): The number of sparse sensor locations to simulate.\n",
    "        va (int): Seed for the random sensor locations (variable kind).\n",
    "        sample_idx (int): Index of the sample from the test set to plot.\n",
    "    \"\"\"\n",
    "    \n",
    "    dim_1 = 128 # Latitude dimension\n",
    "    dim_2 = 48  # Longitude dimension\n",
    "    model_save_path = './Model_ResNet_2Dxysec_weights.pth'\n",
    "    \n",
    "    print(f\"--- Starting Inference: Snapshots={num_snapshots}, Sensors={sen_num}, Sample={sample_idx} ---\")\n",
    "\n",
    "    ## 1. Data Loading and Setup\n",
    "    try:\n",
    "        xcor = pd.read_csv('./record_x.csv', header=None, delim_whitespace=True).values\n",
    "        ycor = pd.read_csv('./record_y.csv', header=None, delim_whitespace=True).values\n",
    "        xc = xcor[0:dim_1, 0]\n",
    "        yc = ycor[0:dim_2, 0]\n",
    "        with open(\"./ch_2Dxysec.pickle\", 'rb') as f:\n",
    "            omg_flc_all = pickle.load(f)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"ERROR: Data file not found for loading: {e.filename}. Cannot proceed.\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Check if we have enough snapshots\n",
    "    if num_snapshots > omg_flc_all.shape[0]:\n",
    "        print(f\"ERROR: Requested snapshots ({num_snapshots}) exceeds available data ({omg_flc_all.shape[0]}).\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    ## 2. Preprocessing and Sparse Sampling\n",
    "    x_ref, y_ref = np.meshgrid(yc, xc)\n",
    "    total_samples = num_snapshots\n",
    "    X_ki = np.zeros((total_samples, dim_1, dim_2, 2))\n",
    "    y_ki = np.zeros((total_samples, dim_1, dim_2, 1))\n",
    "\n",
    "    for t in tqdm(range(num_snapshots), desc=\"Preprocessing Snapshots\"):\n",
    "        # Ground Truth\n",
    "        y_ki[t, :, :, 0] = omg_flc_all[t, :, :, 0]\n",
    "        \n",
    "        # Sparse Locations (Input Channel 0: Nearest Neighbor Interpolation)\n",
    "        np.random.seed(va) \n",
    "        sparse_locations_lat = np.random.randint(dim_1, size=sen_num)\n",
    "        sparse_locations_lon = np.random.randint(dim_2, size=sen_num)\n",
    "\n",
    "        sparse_data = np.zeros(sen_num)\n",
    "        for s in range(sen_num):\n",
    "            sparse_data[s] = omg_flc_all[t, :, :, 0][\n",
    "                int(sparse_locations_lat[s]), int(sparse_locations_lon[s])\n",
    "            ]\n",
    "\n",
    "        sparse_locations_ex = np.zeros((sen_num, 2))\n",
    "        for i in range(sen_num):\n",
    "            sparse_locations_ex[i, 0] = xc[int(sparse_locations_lat[i])]\n",
    "            sparse_locations_ex[i, 1] = yc[int(sparse_locations_lon[i])]\n",
    "\n",
    "        grid_z0 = griddata(sparse_locations_ex, sparse_data, (y_ref, x_ref), method='nearest')\n",
    "        X_ki[t, :, :, 0] = grid_z0\n",
    "\n",
    "        # Mask Image (Input Channel 1: Sensor Mask)\n",
    "        mask_img = np.zeros(grid_z0.shape)\n",
    "        for i in range(sen_num):\n",
    "            mask_img[int(sparse_locations_lat[i]), int(sparse_locations_lon[i])] = 1\n",
    "        X_ki[t, :, :, 1] = mask_img\n",
    "\n",
    "    ## 3. Train-Test Split and Tensor Conversion\n",
    "    X_train_np, X_test_np, y_train_np, y_test_np = train_test_split(\n",
    "        X_ki, y_ki, test_size=0.3, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Convert to Tensors and permute for PyTorch (N, H, W, C) -> (N, C, H, W)\n",
    "    X_test_tensor = torch.from_numpy(X_test_np).float().permute(0, 3, 1, 2).to(device)\n",
    "    y_test_tensor = torch.from_numpy(y_test_np).float().permute(0, 3, 1, 2).to(device)\n",
    "    \n",
    "    # Check if the requested sample index is valid\n",
    "    if sample_idx >= X_test_tensor.shape[0] or sample_idx < 0:\n",
    "        print(f\"ERROR: Invalid sample_idx ({sample_idx}). Must be between 0 and {X_test_tensor.shape[0]-1}.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "    ## 4. Model Loading and Inference\n",
    "    model = ResNetReconstructor(dim_1, dim_2).to(device)\n",
    "    \n",
    "    try:\n",
    "        model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "        model.eval() # Set model to evaluation mode\n",
    "        print(f\"Successfully loaded model weights from {model_save_path}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: Model weights file not found at {model_save_path}. Cannot proceed.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    print(f\"Generating prediction for sample index {sample_idx} from the test set...\")\n",
    "    \n",
    "    x_sample = X_test_tensor[sample_idx:sample_idx+1]\n",
    "    y_true = y_test_tensor[sample_idx]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred_tensor = model(x_sample)\n",
    "\n",
    "    ## 5. Prepare for Plotting\n",
    "    x_input_np = x_sample.cpu().numpy()[0, 0, :, :] \n",
    "    x_mask_np = x_sample.cpu().numpy()[0, 1, :, :] \n",
    "    y_true_np = y_true.cpu().numpy()[0, :, :]      \n",
    "    y_pred_np = y_pred_tensor.cpu().numpy()[0, 0, :, :] \n",
    "\n",
    "    ## 6. Plotting\n",
    "    def plot_field(data, title, ax):\n",
    "        \"\"\"Utility function to plot a 2D field with consistent settings.\"\"\"\n",
    "        # Use vmin/vmax from ground truth for consistent coloring across plots\n",
    "        v_min = y_true_np.min()\n",
    "        v_max = y_true_np.max()\n",
    "        \n",
    "        im = ax.imshow(data, cmap='coolwarm', origin='lower', vmin=v_min, vmax=v_max)\n",
    "        ax.set_title(title)\n",
    "        ax.axis('off')\n",
    "        return im\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    im1 = plot_field(y_true_np, \"A) Ground Truth Field\", axes[0])\n",
    "\n",
    "    im2 = plot_field(x_input_np, \"B) Nearest Neighbor Input\", axes[1])\n",
    "    sensor_locs = np.argwhere(x_mask_np == 1)\n",
    "    if sensor_locs.size > 0:\n",
    "        # Scatter plot for sensor locations\n",
    "        axes[1].scatter(sensor_locs[:, 1], sensor_locs[:, 0], c='k', marker='.', s=10, label='Sensors')\n",
    "        axes[1].legend(loc='upper right', framealpha=0.7)\n",
    "\n",
    "    im3 = plot_field(y_pred_np, \"C) ResNet Reconstruction\", axes[2])\n",
    "\n",
    "    fig.subplots_adjust(right=0.9)\n",
    "    # Add a single colorbar for all plots\n",
    "    cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "    fig.colorbar(im1, cax=cbar_ax, label='Field Value')\n",
    "\n",
    "    plt.suptitle(f\"Field Reconstruction Comparison (Snapshots={num_snapshots}, Sensors={sen_num}, Sample {sample_idx})\", fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "    ## 7. Calculate and Print Error\n",
    "    error = np.mean((y_true_np - y_pred_np)**2)\n",
    "    print(f\"\\nPrediction MSE (on this sample): {error:.6f}\")\n",
    "    \n",
    "    return error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rppg-toolbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
